[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Home",
    "section": "",
    "text": "Eastview High School\nSt. Olaf College\n\nMajor: Environmental Studies (Social Science)\nConcentration: Statistics and Data Science"
  },
  {
    "objectID": "about.html#jenna-graff",
    "href": "about.html#jenna-graff",
    "title": "Home",
    "section": "",
    "text": "Eastview High School\nSt. Olaf College\n\nMajor: Environmental Studies (Social Science)\nConcentration: Statistics and Data Science"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Eastview High School\nSt. Olaf College\n\nMajor: Environmental Studies (Social Science)\nConcentration: Statistics and Data Science"
  },
  {
    "objectID": "index.html#jenna-graff",
    "href": "index.html#jenna-graff",
    "title": "Home",
    "section": "",
    "text": "Eastview High School\nSt. Olaf College\n\nMajor: Environmental Studies (Social Science)\nConcentration: Statistics and Data Science"
  },
  {
    "objectID": "maps.html",
    "href": "maps.html",
    "title": "Mini-Project 1",
    "section": "",
    "text": "February 28th, 2024\n\n\nUS States\n\nIntroduction\nThe dataset that I found to join with our US states data is from the Urban Data Catalog. This data aims to measure the intersections of climate change, food system resilience, and racial equity. Variables measured include household food insecurity rates, costs per meal, percentage of households receiving SNAP, agricultural production, and percentage of households with low store access. A full pdf with variable definitions can be found here.\n\n\nMap\nI chose to make my map measuring the average cost per meal in each US state.\n\n\n\n\n\n\n\nSummary\nFrom this map, we can visualize that high meal costs correlate more strongly with states on the coasts of the US. Costs range from about $2.90 to $4.50. Average meal prices are highest in District of Columbia, Massachusetts, and Rhode Island. Lowest prices are in Kentucky, Texas, and Indiana. The following tables show the exact average costs for the five highest and five lowest states.\n\n\n\n\n\nstate_name\navg_cost_per_meal\n\n\n\n\ndistrict of columbia\n4.490000\n\n\nmassachusetts\n4.201429\n\n\nrhode island\n4.174000\n\n\nvermont\n4.045714\n\n\nconnecticut\n3.906250\n\n\n\n\n\n\n\n\n\n\n\n\nstate_name\navg_cost_per_meal\n\n\n\n\nkentucky\n2.906000\n\n\ntexas\n2.930669\n\n\nindiana\n2.950761\n\n\narkansas\n2.972533\n\n\nwest virginia\n3.021818\n\n\n\n\n\n\n\n\n\n\nWisconsin Districts\n\nIntroduction\nIn February of 2024, Wisconsin’s governor signed an act that will begin the process of redistricting. Wisconsin’s districts have been considered some of the most gerrymandered districts in the country, since the districts were decided in 2011. This has cemented a republican majority, even if they represent close to, or even less than 50% of voters. This new map of congressional districts may change the results of following elections in Wisconsin.\n\n\nMaps\nThe following two maps show the election results in the house of representatives in 2016. This first one shows which party won in each district.\n\n\n\n\n\nThe second map shows the margins by which the party won that district.\n\n\n\n\n\n\n\nSummary\nIn these maps, particularly the second one, it can be seen that republicans had close margins in their races, sometimes winning by only a little over 50%. This is best seen in district 6. Democrats are clustered more heavily in districts 2 and 3. How these margins will change with new congressional district lines will be interesting with the coming 2024 election.\n\n\n\nSources\n\nFederal Election Commission\nUrban Data Catalog"
  },
  {
    "objectID": "maps.html#jenna-graff",
    "href": "maps.html#jenna-graff",
    "title": "Home",
    "section": "",
    "text": "Eastview High School\nSt. Olaf College\n\nMajor: Environmental Studies (Social Science)\nConcentration: Statistics and Data Science"
  },
  {
    "objectID": "maps2.html",
    "href": "maps2.html",
    "title": "Wisconsin Congressional Districts",
    "section": "",
    "text": "maps about wisconsin :/"
  },
  {
    "objectID": "simulation_snowfall.html#snowfall-in-2024",
    "href": "simulation_snowfall.html#snowfall-in-2024",
    "title": "Mini-Project 2",
    "section": "Snowfall in 2024",
    "text": "Snowfall in 2024\n#####source: Minnesota DNR\nThe amount of snowfall this year so far (from the months of October through February) has amounted to 14.3 inches. This year, it has seemed like much less than usual, so I’ve been looking through Minnesota’s Department of Natural Resources data in the Twin Cities. I chose to run simulations using this data to find where this year’s snowfall lies in comparison to other years to see if it is truly statistically less snow than other years.\nThis first graph provides an initial look at how much snow the Twin Cities have gotten each year since 1884.\n\n\n\n\n\nThe data seems to be slightly right-skewed, with possible high outliers. Of course, this data would change with inclusion of the months March and April, but as those haven’t happened yet in 2024, they can’t yet be compared to this year.\nHere are the statistics of these data:\n\n\n\n\n\nmean\nsd\nn\n\n\n\n\n34.20143\n15.11997\n140\n\n\n\n\n\n\n\nThis is the code I used to run a simulation and create a randomized data set of snowfall in 140 years.\n\nsimulated_winters &lt;- vector(\"double\", 1000)\nfor(i in 1:1000) {\n  single_sample &lt;- sample(snowfall$winter)\n  winter_samples &lt;- cbind(snowfall, single_sample)\n  summary_snowfall_sample &lt;- winter_samples |&gt;\n    group_by(single_sample) |&gt;\n    summarize(mean = mean(winter))\n  simulated_winters[[i]] &lt;- summary_snowfall_sample[[2]][2]\n}\n\n\nsimulated_tibble &lt;- tibble(simulated_winters = simulated_winters)\nggplot(simulated_tibble, aes(x = simulated_winters)) +\n  geom_histogram(bins = 25) \n\n\n\n\nThis graph shows snowfall for the whole year, not just the months October through February.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nOne potential shortcoming of the simulation I created is that the data doesn’t cover months that often get large amounts of snowfall. If I were to run this again in two months with data from March and April, the results might change. As this graph shows, there are less gaps\ndeleted stuff:"
  },
  {
    "objectID": "simulation_snowfall.html#results",
    "href": "simulation_snowfall.html#results",
    "title": "Mini-Project 2",
    "section": "Results",
    "text": "Results\nUsing this new randomized data, I created a histogram.\n\n\n\n\n\nUsing the simulation data, we can pull the p-value of this year’s snowfall to see if it falls within the lower 5% of the spread.\n\np_value &lt;- sum(abs(simulated_diffs) &gt;= abs(observed_diff)) / 1000\np_value\n\n[1] 0.189"
  },
  {
    "objectID": "simulation_snowfall.html#discussion",
    "href": "simulation_snowfall.html#discussion",
    "title": "Mini-Project 2",
    "section": "Discussion",
    "text": "Discussion\n\nStatistically Insignifiant Results\nBecause of the p-value this simulation produced,\n\n\nWhat I would do differently if I ran this simulation again\n\nIncomplete Data\nThis graph shows snowfall for the whole year, not just the months October through February.\n\n\n\n\n\nOne potential shortcoming of the simulation I created is that the data doesn’t cover months that often get large amounts of snowfall. If I were to run this again in two months with data from March and April, the results might change. As this graph shows, there are less gaps when including all of the months, and it would increase the mean, and alter the standard deviation."
  },
  {
    "objectID": "simulation_snowfall.html#simulation",
    "href": "simulation_snowfall.html#simulation",
    "title": "Mini-Project 2",
    "section": "Simulation",
    "text": "Simulation\nThis is the code I used to run a simulation and create a randomized data set of snowfall in 140 years.\nFirst, this chunk shows the true difference between 2023-2024 season’s snowfall, and the snowfall each season from 1884-2023. This is an observed difference of about 4 inches each month. This means that on average, this winter season has had 4 inches less snow than other months on average.\n\nsnowfall_summary &lt;- snowfall |&gt;\n  group_by(year_group) |&gt;\n  summarize(mean_snowfall = mean(snow_per_month))\nobserved_diff &lt;- snowfall_summary[[2]][2] - snowfall_summary[[2]][1]\n\nThe next step in this simulation\n\nsimulated_diffs &lt;- vector(\"double\", 1000)\nfor(i in 1:1000) {\n  snowfall_summary &lt;- snowfall |&gt;\n    mutate(year_group = sample(year_group)) |&gt;\n    group_by(year_group) |&gt;\n    summarize(mean_snowfall = mean(snow_per_month))\n  simulated_diffs[[i]] &lt;- snowfall_summary[[2]][2] - snowfall_summary[[2]][1]\n}"
  },
  {
    "objectID": "simulation_snowfall.html",
    "href": "simulation_snowfall.html",
    "title": "Mini-Project 2",
    "section": "",
    "text": "March 22nd, 2024\n\n\nSnowfall in 2023-2024\n\nSource: Minnesota DNR\n\n\nIntroduction\nThe amount of snowfall this year so far (from the months of October through February) has amounted to 14.3 inches, and has seemed like much less than usual. I decided for this project to look through Minnesota’s Department of Natural Resources data in the Twin Cities and run statistical tests comparing this year to other years. I chose to run simulations to find where this year’s snowfall lies in comparison to other years to see if it is truly statistically less snow than other years.\nBefore doing any analysis on this data, it needed to be cleaned. The columns were mostly character vectors, with some double vectors. This made it difficult to pivot, parse, and convert missing data to NAs; each step had to be done to each column instead of the whole data set at once. The values ‘T’ for trace needed to be converted to zeros, and ‘M’ for missing needed to be changed into NA values. Finally, parse_number() changed the character vectors into double vectors, allowing R to find the mean and other statistics. This is the function I attempted to use:\n\nfix_columns &lt;- function(data, x) {\n  data |&gt;\n    mutate(x = ifelse({{ x }} == \"M\", NA, {{ x }}),\n           x = ifelse({{ x }} == \"T\", 0, {{ x }}),\n           x = ifelse({{ x }} == \"T*\", NA, {{ x }}),\n           x = parse_number({{ x }}))\n}\n\nThis first graph provides an initial look at how much snow the Twin Cities have gotten each year since 1884.\n\n\n\n\n\nThe data seems to be right-skewed, with possible high outliers. Of course, this data would change with inclusion of the months March and April, but as those haven’t happened yet in 2024, they can’t yet be compared to this year.\n\n\nSimulation\nThis is the code I used to run a simulation and create a randomized data set of snowfall in 140 years.\nFirst, this chunk shows the true difference between 2023-2024 season’s snowfall, and the snowfall each season from 1884-2023. This is an observed difference of about 4 inches each month. This means that on average, this winter season has had 4 inches less snow than other months on average. This is my alternate hypothesis.\n\nsnowfall_summary &lt;- snowfall |&gt;\n  group_by(year_group) |&gt;\n  summarize(mean_snowfall = mean(snow_per_month))\nobserved_diff &lt;- snowfall_summary[[2]][2] - snowfall_summary[[2]][1]\n\nThe next step in this simulation is to create simulated data for each year grouping: both 2023-2024 and 1884-1885 through 2022-2023. This multiplies our original observed difference by 1000, assuming that the true difference is zero. This is the null hypothesis, in contrast to my alternate hypothesis in the chunk above.\n\nsimulated_diffs &lt;- vector(\"double\", 1000)\nfor(i in 1:1000) {\n  snowfall_summary &lt;- snowfall |&gt;\n    mutate(year_group = sample(year_group)) |&gt;\n    group_by(year_group) |&gt;\n    summarize(mean_snowfall = mean(snow_per_month))\n  simulated_diffs[[i]] &lt;- snowfall_summary[[2]][2] - snowfall_summary[[2]][1]\n}  \n\n\n\nResults\nUsing this new randomized data, I created a histogram showing the spread of the simulated differences between this season and all other seasons, assuming the null hypothesis. The red vertical line represents the difference of 4 from this year.\n\n\n\n\n\nUsing the simulated data, we can pull the p-value of this year’s snowfall to see if it falls within the upper 5% of the spread.\nThe p-value is 0.182.\n\n\nDiscussion\n\nStatistically Insignifiant Results\nBecause of the p-value this simulation produced at a significance level of 0.05, the amount of snow this year would not be considered significantly less than usual. About 18% of the time that this simulation is run, a difference of 4 inches per month or more will be observed. Therefore, this season’s amount of snowfall isn’t statistically unusual.\n\n\nAreas for Future Research\nThere are a few changes I would make to this simulation if I were to run it again, or if I had more time.\n\nIncomplete Data\nThis graph shows snowfall for the whole year, not just the months October through February.\n\n\n\n\n\nOne potential shortcoming of the simulation I created is that the data doesn’t cover months that often get large amounts of snowfall. If I were to run this again in two months with data from March and April, the results might change. As this graph shows, there are less gaps when including all of the months, and it would increase the mean, and alter the standard deviation.\n\n\nOther Applications\nI would also be interested in running this test for last year’s snowfall! In 2022-2023, the Twin Cities got 90.3 inches of snow. From the histogram, this seems like one of the higher years on record. Now that I have this simulation set up, it would be easy to alter it to run different tests, both on this data set, and on others I find."
  }
]